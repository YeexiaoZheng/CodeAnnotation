{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在colab上取消注释这一cell\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/CodeAnnotation\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from Trainer import Trainer\n",
    "from transformers import RobertaModel, T5ForConditionalGeneration\n",
    "from transformers import (AdamW, get_linear_schedule_with_warmup)\n",
    "\n",
    "from utils.common import read_data, write_to_file, save_checkpoint\n",
    "from utils.DataProcess import Processor\n",
    "from Config import config\n",
    "from Model import Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config.device = device\n",
    "\n",
    "# make dir if output_dir not exist\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.makedirs(config.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config.model_type, config.model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Processor(config)\n",
    "\n",
    "train_data = read_data(config.train_data_path)\n",
    "train_loader = processor(train_data, config.train_params, 'train')\n",
    "\n",
    "val_data = read_data(config.val_data_path)\n",
    "val_loader = processor(val_data, config.val_params, 'eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer\n",
    "\n",
    "if config.model_type.lower() == 'codet5':   \n",
    "    model = T5ForConditionalGeneration.from_pretrained(config.model_path)\n",
    "else:\n",
    "    # Encoder\n",
    "    encoder = RobertaModel.from_pretrained(config.model_path)\n",
    "    model_config = encoder.config\n",
    "    # Decoder\n",
    "    decoder_layer = nn.TransformerDecoderLayer(d_model=model_config.hidden_size, nhead=model_config.num_attention_heads)\n",
    "    decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "    # Seq2Seq\n",
    "    model = Seq2Seq(encoder=encoder, decoder=decoder, config=model_config,\n",
    "                beam_size=config.beam_size, max_length=config.max_target_length,\n",
    "                sos_id=tokenizer.cls_token_id, eos_id=tokenizer.sep_token_id)\n",
    "                \n",
    "if config.load_model_path is not None:\n",
    "    print(\"reload model from {}\".format(config.load_model_path))\n",
    "    model.load_state_dict(torch.load(config.load_model_path))\n",
    "    \n",
    "model.to(device)\n",
    "print('model built')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = config.epoch\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': config.weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
    "        'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate, eps=config.adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=config.warmup_steps,\n",
    "    num_training_steps=(epoch * len(train_loader))\n",
    ")\n",
    "\n",
    "trainer = Trainer(config, processor, model, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_loss_list, all_train_loss_list_detail = [], []\n",
    "val_ppl_list, val_bleu_list = [], []\n",
    "best_ppl = 9999\n",
    "best_bleu = 0\n",
    "\n",
    "for e in range(1, epoch + 1):\n",
    "    print('-' * 20 + ' ' + 'Epoch ' + str(e) + ' ' + '-' * 20)\n",
    "    train_loss, train_loss_list = trainer.train(train_loader)\n",
    "    all_train_loss_list.append(train_loss)\n",
    "    all_train_loss_list_detail.extend(train_loss_list)\n",
    "    print('train loss: {}'.format(train_loss))\n",
    "\n",
    "    val_ppl, val_bleu = trainer.valid(val_loader)\n",
    "    val_ppl_list.append(val_ppl)\n",
    "    val_bleu_list.append(val_bleu)\n",
    "    print('val ppl: {}, val bleu: {}'.format(val_ppl, val_bleu))\n",
    "\n",
    "    # save last checkpoint\n",
    "    save_checkpoint(model, config.output_dir, 'checkpoint-last')\n",
    "\n",
    "    # save best ppl checkpoint\n",
    "    if val_ppl < best_ppl:\n",
    "        best_ppl = val_ppl\n",
    "        save_checkpoint(model, config.output_dir, 'checkpoint-best-ppl')\n",
    "        print('update best ppl: {} and model saved'.format(val_ppl))\n",
    "    \n",
    "    # save best bleu checkpoint\n",
    "    if val_bleu > best_bleu:\n",
    "        best_bleu = val_bleu\n",
    "        save_checkpoint(model, config.output_dir, 'checkpoint-best-bleu')\n",
    "        print('update best bleu: {} and model saved'.format(best_bleu))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_train_loss_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks(range(epoch), range(1, epoch + 1))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(all_train_loss_list_detail)\n",
    "plt.ylabel('loss detail')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks(range(0, len(all_train_loss_list_detail), len(all_train_loss_list_detail) // epoch), range(epoch))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_ppl_list)\n",
    "plt.ylabel('valid ppl')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks(range(epoch), range(1, epoch + 1))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_bleu_list)\n",
    "plt.ylabel('valid bleu')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks(range(epoch), range(1, epoch + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = read_data(config.test_data_path)\n",
    "test_loader = processor(test_examples, config.test_params, 'test')\n",
    "pred_ids = trainer.predict(test_loader)\n",
    "pred_texts = processor.decode(pred_ids)\n",
    "write_to_file(config.output_dir, pred_texts, 'test.output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "625a9e90e125179d2e4e722dbf246d9ce1d0a9c1468b83ede14555db0f731cfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
